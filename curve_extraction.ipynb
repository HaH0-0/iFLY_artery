{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89066df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, csv, json, math, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List, Tuple, Optional\n",
    "from scipy.spatial import cKDTree\n",
    "from skimage.filters import sato   # 或 frangi，均可\n",
    "from skimage.graph import route_through_array\n",
    "from skimage.morphology import skeletonize\n",
    "\n",
    "from scipy.stats import theilslopes\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 若 apt/conda 安装的 tesseract 不在 PATH，请显式指定：\n",
    "# pytesseract.pytesseract.tesseract_cmd = \"/usr/bin/tesseract\"\n",
    "\n",
    "DIGIT_CONFIG_BASE = \"-c tessedit_char_whitelist=-0123456789.,\"\n",
    "NUM_RE = re.compile(r'^[\\-\\+]?[\\d]+(?:[.,]\\d+)?$')\n",
    "\n",
    "def _parse_num(s: str):\n",
    "    s = s.strip().replace('，',',').replace('。','.')\n",
    "    s = s.replace('−','-').replace('–','-').replace('—','-')\n",
    "    s = s.replace(',', '.')\n",
    "    if NUM_RE.match(s):\n",
    "        try: return float(s)\n",
    "        except: return None\n",
    "    return None\n",
    "\n",
    "def save_csv(path, rows, header=None):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        if header: w.writerow(header)\n",
    "        for r in rows: w.writerow(r)\n",
    "\n",
    "def cv2_imread_any(path):\n",
    "    path = str(path)\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        data = np.fromfile(path, dtype=np.uint8)            # Unicode-safe\n",
    "        img = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "    return img\n",
    "\n",
    "def df_to_csv_safe(df, path):\n",
    "    import os, io\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    try:\n",
    "        # 尝试常规 pandas 导出\n",
    "        df.to_csv(path, index=False)\n",
    "    except TypeError as e:\n",
    "        # 某些环境会对 lineterminator 报错，这里兜底用纯手写\n",
    "        with open(path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            # 头\n",
    "            f.write(\",\".join(map(str, df.columns)) + \"\\n\")\n",
    "            # 行\n",
    "            for row in df.itertuples(index=False, name=None):\n",
    "                f.write(\",\".join(\"\" if x is None else str(x) for x in row) + \"\\n\")\n",
    "\n",
    "\n",
    "def plot_img(img, title=None, figsize=(5,5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    if title: plt.title(title)\n",
    "    plt.axis('off'); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8db2dab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DePlot 模块不可用，将在运行时自动回退到 OCR 方案。 No module named 'transformers'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    from transformers import Pix2StructForConditionalGeneration, Pix2StructProcessor\n",
    "    _DEPLOT_OK = True\n",
    "except Exception as e:\n",
    "    print(\"DePlot 模块不可用，将在运行时自动回退到 OCR 方案。\", e)\n",
    "    _DEPLOT_OK = False\n",
    "\n",
    "class DePlotWrapper:\n",
    "    def __init__(self, model_id: str = \"google/deplot\"):\n",
    "        if not _DEPLOT_OK:\n",
    "            self.model = None\n",
    "            self.processor = None\n",
    "            return\n",
    "        try:\n",
    "            self.processor = Pix2StructProcessor.from_pretrained(model_id)\n",
    "            self.model = Pix2StructForConditionalGeneration.from_pretrained(model_id)\n",
    "            self.model.eval()\n",
    "        except Exception as e:\n",
    "            print(\"加载 DePlot 失败，将回退到 OCR 方案。\", e)\n",
    "            self.model = None\n",
    "            self.processor = None\n",
    "\n",
    "    def available(self):\n",
    "        return (self.model is not None) and (self.processor is not None)\n",
    "\n",
    "    '''\n",
    "    def infer_table(self, img_bgr):\n",
    "        \"\"\"返回 DataFrame；失败返回 None。\"\"\"\n",
    "        if not self.available():\n",
    "            return None\n",
    "        from PIL import Image\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "        pil = Image.fromarray(img_rgb)\n",
    "        prompt = \"Generate the underlying data table of the figure below:\"\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = self.processor(images=pil, text=prompt, return_tensors=\"pt\")\n",
    "            outputs = self.model.generate(**inputs, max_new_tokens=512)\n",
    "            txt = self.processor.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        # 解析 markdown/CSV 风格结果\n",
    "        lines = [l.strip() for l in txt.splitlines() if l.strip()]\n",
    "        rows = []\n",
    "        for ln in lines:\n",
    "            if \"|\" in ln:\n",
    "                cols = [c.strip() for c in ln.strip(\"|\").split(\"|\")]\n",
    "                rows.append(cols)\n",
    "            elif \",\" in ln:\n",
    "                rows.append([c.strip() for c in ln.split(\",\")])\n",
    "\n",
    "        if not rows:\n",
    "            return None\n",
    "\n",
    "        header = [c if c else f\"col{i}\" for i, c in enumerate(rows[0])]\n",
    "        data = [r for r in rows[1:] if len(r) == len(header)]\n",
    "        if not data:\n",
    "            return None\n",
    "\n",
    "        df = pd.DataFrame(data, columns=header)\n",
    "        # 尝试转数值\n",
    "        for col in df.columns:\n",
    "            try:\n",
    "                df[col] = df[col].map(lambda s: _parse_num(str(s)))\n",
    "            except Exception:\n",
    "                pass\n",
    "        return df\n",
    "    '''\n",
    "\n",
    "    # —— 直接替换 DePlotWrapper 里的 infer_table 方法 —— \n",
    "    def infer_table(self, img_bgr, axis_hint=(\"x\",\"z\"), debug_save_txt=None):\n",
    "        \"\"\"\n",
    "        尝试多提示词和更鲁棒的解析。\n",
    "        axis_hint=(\"x\",\"z\") 表示横轴名字和纵轴名字，仅用于提示，不影响返回顺序。\n",
    "        返回: DataFrame 或 None；如 debug_save_txt 传路径，会把原始生成文本落盘。\n",
    "        \"\"\"\n",
    "        if not self.available():\n",
    "            return None\n",
    "\n",
    "        from PIL import Image\n",
    "        import torch, re, pandas as pd, numpy as np\n",
    "\n",
    "        # 1) 只喂“绘图区”给模型（减少干扰）\n",
    "        roi = find_plot_roi(img_bgr)\n",
    "        x0,y0,x1,y1 = roi\n",
    "        crop = img_bgr[y0:y1, x0:x1]\n",
    "        img_rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "        pil = Image.fromarray(img_rgb)\n",
    "\n",
    "        # 2) 多提示词重试（从“只要CSV”到“允许 Markdown 表”逐步放松）\n",
    "        prompts = [\n",
    "            f\"Return ONLY CSV with two numeric columns: {axis_hint[0]}, {axis_hint[1]}. No headers, no text, one pair per line.\",\n",
    "            f\"Output comma-separated numeric pairs ({axis_hint[0]}, {axis_hint[1]}), one per line. No extra text.\",\n",
    "            f\"Generate the underlying data table of the figure below. Use CSV or Markdown table with numeric values only.\",\n",
    "        ]\n",
    "\n",
    "        txt_raw = None\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    inputs = self.processor(\n",
    "                        images=pil, text=prompt, return_tensors=\"pt\", max_patches=1024\n",
    "                    )\n",
    "                    outputs = self.model.generate(\n",
    "                        **inputs,\n",
    "                        max_new_tokens=1024,\n",
    "                        num_beams=3,\n",
    "                        early_stopping=True,\n",
    "                        no_repeat_ngram_size=3,\n",
    "                        length_penalty=0.1,\n",
    "                    )\n",
    "                    txt_raw = self.processor.decode(outputs[0], skip_special_tokens=True)\n",
    "                # 解析\n",
    "                df = _parse_deplot_text_to_df(txt_raw)\n",
    "                if isinstance(df, pd.DataFrame) and df.shape[1] >= 2:\n",
    "                    # 只取前两列，且保持“第1列= X/Y、第2列= Z”的约定\n",
    "                    v = pd.to_numeric(df.iloc[:,0], errors=\"coerce\")\n",
    "                    z = pd.to_numeric(df.iloc[:,1], errors=\"coerce\")\n",
    "                    good = (~v.isna()) & (~z.isna())\n",
    "                    if good.sum() >= 10:\n",
    "                        out = pd.DataFrame({\"z\": z[good].values, axis_hint[0]: v[good].values})\n",
    "                        # 排序、去重（按 z）\n",
    "                        order = np.argsort(out[\"z\"].values)\n",
    "                        out = out.iloc[order]\n",
    "                        out = out.drop_duplicates(subset=[\"z\"], keep=\"first\")\n",
    "                        if debug_save_txt:\n",
    "                            os.makedirs(os.path.dirname(debug_save_txt), exist_ok=True)\n",
    "                            with open(debug_save_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "                                f.write(txt_raw)\n",
    "                        # 返回成你外层需要的两列顺序（[\"z\", \"x\"] 或 [\"z\", \"y\"]）\n",
    "                        return out[[\"z\", axis_hint[0]]]\n",
    "            except Exception as e:\n",
    "                # 当前提示失败就换下一个\n",
    "                continue\n",
    "\n",
    "        # 全部提示都没成功解析：返回 None，让上层自动回退到 OCR\n",
    "        if debug_save_txt and txt_raw is not None:\n",
    "            os.makedirs(os.path.dirname(debug_save_txt), exist_ok=True)\n",
    "            with open(debug_save_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(txt_raw)\n",
    "        return None\n",
    "\n",
    "    @staticmethod \n",
    "    def _parse_deplot_text_to_df(txt: str):\n",
    "        \"\"\"\n",
    "        兼容三类输出：\n",
    "        1) 纯 CSV（每行两个数）\n",
    "        2) Markdown 表（'| a | b |'）\n",
    "        3) 混合文本里散落的数字对（正则兜底）\n",
    "        返回: pandas.DataFrame 或 None\n",
    "        \"\"\"\n",
    "        import pandas as pd, re\n",
    "        if not txt or not isinstance(txt, str) or not txt.strip():\n",
    "            return None\n",
    "\n",
    "        lines = [l.strip() for l in txt.splitlines() if l.strip()]\n",
    "        rows = []\n",
    "\n",
    "        # A) Markdown 表\n",
    "        md_rows = []\n",
    "        for ln in lines:\n",
    "            if \"|\" in ln:\n",
    "                cols = [c.strip() for c in ln.strip(\"|\").split(\"|\")]\n",
    "                # 过滤掉 '---' 这种分隔行\n",
    "                if any(set(c) == {\"-\"} for c in cols):\n",
    "                    continue\n",
    "                md_rows.append(cols)\n",
    "        if md_rows:\n",
    "            # 去掉可能的表头\n",
    "            if not _row_is_numeric(md_rows[0]):\n",
    "                md_rows = md_rows[1:]\n",
    "            md_rows = [r for r in md_rows if _row_is_numeric(r)]\n",
    "            if md_rows:\n",
    "                return pd.DataFrame(md_rows)\n",
    "\n",
    "        # B) 纯 CSV（逗号/分号/空格）\n",
    "        csv_rows = []\n",
    "        for ln in lines:\n",
    "            if \",\" in ln or \";\" in ln:\n",
    "                parts = re.split(r\"[;,]\", ln)\n",
    "                parts = [p.strip() for p in parts if p.strip()]\n",
    "                if len(parts) >= 2 and _row_is_numeric(parts[:2]):\n",
    "                    csv_rows.append(parts[:2])\n",
    "            else:\n",
    "                # 允许用空格分隔\n",
    "                parts = ln.split()\n",
    "                if len(parts) >= 2 and _row_is_numeric(parts[:2]):\n",
    "                    csv_rows.append(parts[:2])\n",
    "        if csv_rows:\n",
    "            return pd.DataFrame(csv_rows)\n",
    "\n",
    "        # C) 正则兜底：抓每行里的“两个数”\n",
    "        reg_rows = []\n",
    "        num = r\"[+\\-]?\\d+(?:\\.\\d+)?\"\n",
    "        for ln in lines:\n",
    "            m = re.findall(num, ln)\n",
    "            if len(m) >= 2:\n",
    "                reg_rows.append(m[:2])\n",
    "        if reg_rows:\n",
    "            return pd.DataFrame(reg_rows)\n",
    "\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def _row_is_numeric(it):\n",
    "        import math\n",
    "        try:\n",
    "            a = float(str(it[0]).replace(\",\", \".\"))\n",
    "            b = float(str(it[1]).replace(\",\", \".\"))\n",
    "            return math.isfinite(a) and math.isfinite(b)\n",
    "        except:\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cb62deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_plot_roi(img, fallback_margin=0.05):\n",
    "    h, w = img.shape[:2]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ed = cv2.Canny(gray, 60, 160)\n",
    "    ed = cv2.dilate(ed, np.ones((3,3),np.uint8), 1)\n",
    "    cnts, _ = cv2.findContours(ed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    best, best_area = None, 0\n",
    "    for c in cnts:\n",
    "        x,y,wc,hc = cv2.boundingRect(c)\n",
    "        area = wc*hc\n",
    "        if 0.25*h*w < area < 0.98*h*w and area > best_area:\n",
    "            best_area, best = area, (x,y,x+wc,y+hc)\n",
    "    if best is None:\n",
    "        m = int(fallback_margin*min(h,w))\n",
    "        return (m,m,w-m,h-m)\n",
    "    return best\n",
    "\n",
    "def _skeletonize(bin_u8):\n",
    "    sk = skeletonize((bin_u8>0).astype(bool))\n",
    "    return (sk.astype(np.uint8)*255)\n",
    "\n",
    "\n",
    "def extract_curve_points(img_bgr, roi=None, color_hint=None):\n",
    "    if roi is None: roi = find_plot_roi(img_bgr)\n",
    "    x0,y0,x1,y1 = roi\n",
    "    crop = img_bgr[y0:y1, x0:x1]\n",
    "    lab = cv2.cvtColor(crop, cv2.COLOR_BGR2LAB)\n",
    "    L,A,B = cv2.split(lab)\n",
    "    chroma = np.sqrt((A-128.0)**2 + (B-128.0)**2)\n",
    "    hsv = cv2.cvtColor(crop, cv2.COLOR_BGR2HSV)\n",
    "    V = hsv[:,:,2]\n",
    "    c_thr = np.percentile(chroma, 99) * 0.35\n",
    "    v_thr = np.percentile(V, 75) * 0.7\n",
    "    mask = (chroma>c_thr) & (V>v_thr)\n",
    "    if color_hint in ('red','blue','green'):\n",
    "        H,S,Val = cv2.split(hsv)\n",
    "        if color_hint=='red':\n",
    "            hint = ((H<10)|(H>170))&(S>50)&(Val>50)\n",
    "        elif color_hint=='blue':\n",
    "            hint = (H>90)&(H<140)&(S>50)&(Val>50)\n",
    "        else:\n",
    "            hint = (H>35)&(H<85)&(S>50)&(Val>50)\n",
    "        mask = mask | hint\n",
    "    bin_u8 = (mask.astype(np.uint8)*255)\n",
    "    bin_u8 = cv2.morphologyEx(bin_u8, cv2.MORPH_OPEN, np.ones((3,3),np.uint8), 1)\n",
    "    bin_u8 = cv2.morphologyEx(bin_u8, cv2.MORPH_DILATE, np.ones((3,3),np.uint8), 1)\n",
    "\n",
    "    # 兜底：主色相 + Canny\n",
    "    ys,xs = np.where(bin_u8>0)\n",
    "    if len(xs)<50:\n",
    "        H,S,Val = cv2.split(hsv)\n",
    "        topk = np.argsort(chroma.ravel())[-max(1000, chroma.size//20):]\n",
    "        hue_peak = np.bincount(H.ravel()[topk], minlength=181).argmax()\n",
    "        lower = np.array([max(hue_peak-10,0), 30, 50])\n",
    "        upper = np.array([min(hue_peak+10,180), 255, 255])\n",
    "        mask2 = cv2.inRange(hsv, lower, upper)\n",
    "        mask2 = cv2.morphologyEx(mask2, cv2.MORPH_OPEN, np.ones((3,3),np.uint8), 1)\n",
    "        mask2 = cv2.GaussianBlur(mask2, (3,3), 0)\n",
    "        edges = cv2.Canny(mask2, 30, 80)\n",
    "        bin_u8 = edges\n",
    "    bin_u8 = _largest_component(bin_u8)\n",
    "    bin_u8 = _skeletonize(bin_u8)\n",
    "    path = _longest_path_on_skeleton(bin_u8)\n",
    "    if len(path)==0: return path, roi\n",
    "    path[:,0] += x0; path[:,1] += y0\n",
    "    return path, roi\n",
    "\n",
    "def save_overlay(path, img, roi, pts):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    vis = img.copy()\n",
    "    step = max(1, len(pts)//1500) if len(pts)>0 else 1\n",
    "    for (px,py) in pts[::step]:\n",
    "        cv2.circle(vis, (int(px), int(py)), 1, (0,255,0), -1)\n",
    "    x0,y0,x1,y1 = roi\n",
    "    cv2.rectangle(vis, (x0,y0), (x1,y1), (0,255,255), 2)\n",
    "    cv2.imwrite(path, vis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "881fd2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, cv2\n",
    "from collections import deque\n",
    "from scipy.stats import theilslopes\n",
    "\n",
    "# --- ROI 稍微外扩，避免线贴边被切掉 ---\n",
    "def _pad_roi(roi, img_shape, pad=4):\n",
    "    x0,y0,x1,y1 = roi\n",
    "    H,W = img_shape[:2]\n",
    "    return max(0,x0-pad), max(0,y0-pad), min(W,x1+pad), min(H,y1+pad)\n",
    "\n",
    "# --- 去网格：提取水平/竖直长线并减掉，再做边缘 ---\n",
    "def _remove_grid(gray):\n",
    "    hor = cv2.morphologyEx(gray, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_RECT,(31,1)))\n",
    "    ver = cv2.morphologyEx(gray, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_RECT,(1,31)))\n",
    "    grid = cv2.max(hor, ver)\n",
    "    base = cv2.subtract(gray, grid)\n",
    "    base = cv2.GaussianBlur(base, (3,3), 0)\n",
    "    return base\n",
    "\n",
    "# --- 自动找 hue 峰（高饱和高亮区域） ---\n",
    "def _peak_hues(hsv, sat_thr=60, val_thr=50, topk=3):\n",
    "    H,S,V = cv2.split(hsv)\n",
    "    mask = (S>=sat_thr) & (V>=val_thr)\n",
    "    if np.count_nonzero(mask) < 200: return []\n",
    "    hist,_ = np.histogram(H[mask], bins=181, range=(0,181))\n",
    "    hist = cv2.GaussianBlur(hist.astype(np.float32).reshape(-1,1),(5,1),0).ravel()\n",
    "    peaks = hist.argsort()[::-1][:topk]\n",
    "    # 合并到大色系（红色回绕单独处理）\n",
    "    out=[]; seen=set()\n",
    "    for h in peaks:\n",
    "        if h<10 or h>170: name=\"red\"\n",
    "        elif 35<=h<=85: name=\"green\"\n",
    "        elif 90<=h<=140: name=\"blue\"\n",
    "        else: name=\"other\"\n",
    "        if name not in seen:\n",
    "            seen.add(name); out.append((name,int(h)))\n",
    "    return out\n",
    "\n",
    "def _mask_from_hue(hsv, h_center, band=12, s_min=60, v_min=50):\n",
    "    if h_center < band:\n",
    "        m1 = cv2.inRange(hsv, (0, s_min, v_min), (h_center+band,255,255))\n",
    "        m2 = cv2.inRange(hsv, (180-(band-h_center), s_min, v_min), (180,255,255))\n",
    "        return cv2.bitwise_or(m1,m2)\n",
    "    if h_center+band>180:\n",
    "        m1 = cv2.inRange(hsv, (0, s_min, v_min), ((h_center+band)-180,255,255))\n",
    "        m2 = cv2.inRange(hsv, (h_center-band, s_min, v_min), (180,255,255))\n",
    "        return cv2.bitwise_or(m1,m2)\n",
    "    return cv2.inRange(hsv, (h_center-band, s_min, v_min), (h_center+band,255,255))\n",
    "\n",
    "# --- 最大连通域 ---\n",
    "def _largest_component(mask, min_keep=150):\n",
    "    \"\"\"\n",
    "    输入: mask 可为 bool 或 uint8(0/255)。\n",
    "    输出: uint8 0/255，且仅保留最大连通域（若最大域太小则原样返回）。\n",
    "    \"\"\"\n",
    "    m = mask\n",
    "    if m.dtype != np.uint8:\n",
    "        m = (m > 0).astype(np.uint8)\n",
    "    # 统一成 0/255，后续形态学/可视化更稳\n",
    "    if m.max() == 1:\n",
    "        m = m * 255\n",
    "\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(m, connectivity=8)\n",
    "    if num <= 1:\n",
    "        return m\n",
    "\n",
    "    # 找面积最大（跳过背景0）\n",
    "    idx = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
    "    if stats[idx, cv2.CC_STAT_AREA] < min_keep:\n",
    "        return m\n",
    "\n",
    "    out = np.zeros_like(m)\n",
    "    out[labels == idx] = 255\n",
    "    return out\n",
    "\n",
    "\n",
    "# --- 骨架（首选 ximgproc.thinning，兜底 Zhang-Suen） ---\n",
    "def _skeletonize(bin255):\n",
    "    bin255 = (bin255>0).astype(np.uint8)*255\n",
    "    try:\n",
    "        import cv2.ximgproc as xi\n",
    "        return xi.thinning(bin255)  # 返回0/255\n",
    "    except Exception:\n",
    "        # Zhang-Suen 简化实现\n",
    "        img = (bin255>0).astype(np.uint8)\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed=False\n",
    "            to0=[]\n",
    "            H,W = img.shape\n",
    "            for step in (0,1):\n",
    "                for y in range(1,H-1):\n",
    "                    for x in range(1,W-1):\n",
    "                        if img[y,x]==0: continue\n",
    "                        P = [img[y-1,x],img[y-1,x+1],img[y,x+1],img[y+1,x+1],\n",
    "                             img[y+1,x],img[y+1,x-1],img[y,x-1],img[y-1,x-1]]\n",
    "                        nz = sum(p>0 for p in P)\n",
    "                        if nz<2 or nz>6: continue\n",
    "                        # 0->1 转换次数\n",
    "                        trans = 0\n",
    "                        for i in range(8):\n",
    "                            if P[i]==0 and P[(i+1)%8]>0: trans += 1\n",
    "                        if trans != 1: continue\n",
    "                        if step==0:\n",
    "                            if P[0]*P[2]*P[4]>0: continue\n",
    "                            if P[2]*P[4]*P[6]>0: continue\n",
    "                        else:\n",
    "                            if P[0]*P[2]*P[6]>0: continue\n",
    "                            if P[0]*P[4]*P[6]>0: continue\n",
    "                        to0.append((y,x))\n",
    "                if to0:\n",
    "                    for (yy,xx) in to0: img[yy,xx]=0\n",
    "                    changed=True\n",
    "                    to0=[]\n",
    "        return img*255\n",
    "\n",
    "# --- 取骨架端点 ---\n",
    "def _skeleton_endpoints(skel255):\n",
    "    sk = (skel255>0).astype(np.uint8)\n",
    "    ys,xs = np.where(sk>0)\n",
    "    pts = list(zip(xs,ys))\n",
    "    s = set(pts)\n",
    "    ends=[]\n",
    "    for x,y in pts:\n",
    "        cnt=0\n",
    "        for dx in (-1,0,1):\n",
    "            for dy in (-1,0,1):\n",
    "                if dx==0 and dy==0: continue\n",
    "                if (x+dx,y+dy) in s: cnt+=1\n",
    "        if cnt==1: ends.append((x,y))\n",
    "    return ends\n",
    "\n",
    "# --- 连接近端点（补断裂） ---\n",
    "def _connect_close_endpoints(skel255, max_gap):\n",
    "    sk = (skel255>0).astype(np.uint8)*255\n",
    "    ends = _skeleton_endpoints(sk)\n",
    "    if len(ends)<2: return sk\n",
    "    used=set()\n",
    "    for i in range(len(ends)):\n",
    "        if i in used: continue\n",
    "        xi,yi = ends[i]\n",
    "        best=None; bestd=1e9; bestj=None\n",
    "        for j in range(i+1,len(ends)):\n",
    "            if j in used: continue\n",
    "            xj,yj = ends[j]\n",
    "            d = np.hypot(xi-xj, yi-yj)\n",
    "            if d<bestd:\n",
    "                bestd=d; bestj=j\n",
    "        if bestd<=max_gap and bestj is not None:\n",
    "            cv2.line(sk, (xi,yi), ends[bestj], 255, 1, cv2.LINE_8)\n",
    "            used.add(i); used.add(bestj)\n",
    "    return sk\n",
    "\n",
    "# --- 从骨架取最长路径（像素级） ---\n",
    "def _longest_path_on_skeleton(skel255):\n",
    "    sk = (skel255>0).astype(np.uint8)\n",
    "    ys,xs = np.where(sk>0)\n",
    "    if len(xs)==0: return np.empty((0,2),dtype=int)\n",
    "    pts = list(zip(xs,ys))\n",
    "    idx = {p:i for i,p in enumerate(pts)}\n",
    "    # 建图\n",
    "    nbrs=[[] for _ in pts]\n",
    "    for k,(x,y) in enumerate(pts):\n",
    "        for dx in (-1,0,1):\n",
    "            for dy in (-1,0,1):\n",
    "                if dx==0 and dy==0: continue\n",
    "                q=(x+dx,y+dy)\n",
    "                j=idx.get(q)\n",
    "                if j is not None: nbrs[k].append(j)\n",
    "    # 找端点，否则做“直径”双 BFS\n",
    "    deg = [len(n) for n in nbrs]\n",
    "    endpoints = [i for i,d in enumerate(deg) if d==1]\n",
    "    def bfs(start):\n",
    "        q=deque([start]); dist={start:0}; parent={start:-1}\n",
    "        last=start\n",
    "        while q:\n",
    "            u=q.popleft(); last=u\n",
    "            for v in nbrs[u]:\n",
    "                if v in dist: continue\n",
    "                dist[v]=dist[u]+1; parent[v]=u; q.append(v)\n",
    "        return last, dist, parent\n",
    "    if endpoints:\n",
    "        a=endpoints[0]\n",
    "    else:\n",
    "        a=0\n",
    "    b,_,par = bfs(a)\n",
    "    c,_,par2= bfs(b)\n",
    "    # 回溯 b->c 路径\n",
    "    path=[]\n",
    "    u=c\n",
    "    while u!=-1:\n",
    "        path.append(pts[u]); u=par2.get(u,-1)\n",
    "    return np.array(path, dtype=int)\n",
    "\n",
    "def _kill_border(u8, px=6):\n",
    "    \"\"\"把靠边 px 像素都置 0，杀掉内框/坐标轴\"\"\"\n",
    "    m = u8.copy()\n",
    "    if m.ndim == 3:  # 保护一下三通道\n",
    "        m = cv2.cvtColor(m, cv2.COLOR_BGR2GRAY)\n",
    "    H, W = m.shape\n",
    "    if px > 0:\n",
    "        m[:px, :] = 0; m[-px:, :] = 0; m[:, :px] = 0; m[:, -px:] = 0\n",
    "    return m\n",
    "\n",
    "\n",
    "def _component_touches_border(comp255, px=4, frac=0.25):\n",
    "    M = comp255 > 0\n",
    "    H, W = M.shape\n",
    "    border = np.zeros_like(M, bool)\n",
    "    border[:px,:] = True; border[-px:,:] = True; border[:,:px] = True; border[:,-px:] = True\n",
    "    touch = (M & border).sum()\n",
    "    area  = M.sum()\n",
    "    return area > 0 and (touch / max(area,1)) > frac\n",
    "\n",
    "def _border_penalty(shape, px=6):\n",
    "    H, W = shape\n",
    "    yy = np.minimum(np.arange(H), np.arange(H)[::-1])[:,None]\n",
    "    xx = np.minimum(np.arange(W), np.arange(W)[::-1])[None,:]\n",
    "    d = np.minimum(yy, xx).astype(np.float32)\n",
    "    return (px - np.clip(d, 0, px)) / max(px,1)  # 边缘=1, 内部=0\n",
    "\n",
    "# ---- 新增：骨架剪枝（去掉短枝）----\n",
    "def _prune_skeleton(skel255, min_len=20):\n",
    "    sk = (skel255>0).astype(np.uint8)\n",
    "    H,W = sk.shape\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        ys, xs = np.where(sk>0)\n",
    "        for y,x in zip(ys, xs):\n",
    "            # 统计8邻域\n",
    "            cnt = 0\n",
    "            nbr = []\n",
    "            for dy in (-1,0,1):\n",
    "                for dx in (-1,0,1):\n",
    "                    if dx==0 and dy==0: continue\n",
    "                    yy,xx = y+dy, x+dx\n",
    "                    if 0<=yy<H and 0<=xx<W and sk[yy,xx]>0:\n",
    "                        cnt += 1; nbr.append((yy,xx))\n",
    "            if cnt==1:\n",
    "                # 从这个端点往前走，若很短就剪掉\n",
    "                path = [(y,x)]\n",
    "                py, px = y, x\n",
    "                for _ in range(min_len):\n",
    "                    # 找唯一的下一点\n",
    "                    nxt = []\n",
    "                    for dy in (-1,0,1):\n",
    "                        for dx in (-1,0,1):\n",
    "                            if dx==0 and dy==0: continue\n",
    "                            yy,xx = py+dy, px+dx\n",
    "                            if 0<=yy<H and 0<=xx<W and sk[yy,xx]>0 and (yy,xx) not in path:\n",
    "                                nxt.append((yy,xx))\n",
    "                    if len(nxt)!=1: break\n",
    "                    py,px = nxt[0]\n",
    "                    path.append((py,px))\n",
    "                if len(path) < min_len:\n",
    "                    for yy,xx in path: sk[yy,xx]=0\n",
    "                    changed = True\n",
    "    return sk*255\n",
    "\n",
    "# 2) 新增：计算“贴边比例”（用于评分惩罚）\n",
    "def _border_touch_ratio(path_rc, H, W, thr=3):\n",
    "    xs, ys = path_rc[:,1], path_rc[:,0]   # path_rc 是 (y,x)\n",
    "    hit = ((xs < thr) | (xs > W - 1 - thr) | (ys < thr) | (ys > H - 1 - thr)).sum()\n",
    "    return hit / max(1, len(path_rc))\n",
    "\n",
    "# 3) 修改评分：对贴边路径降权；对颜色候选加成\n",
    "def _score_path(path_rc, H, W, kind=\"edge\"):\n",
    "    if len(path_rc) < 20: \n",
    "        return 0.0\n",
    "    p = path_rc[:, ::-1].astype(np.float32)      # (y,x) -> (x,y) 仅用于差分\n",
    "    diff = np.diff(p, axis=0)\n",
    "    length = np.sum(np.linalg.norm(diff, axis=1))\n",
    "    span = (p[:,0].max() - p[:,0].min()) + (p[:,1].max() - p[:,1].min())\n",
    "    d2 = np.diff(p, n=2, axis=0)\n",
    "    smooth = 1.0 / (np.mean(np.linalg.norm(d2, axis=1)) + 1e-3)\n",
    "\n",
    "    base = 0.6*length + 0.3*span + 0.1*smooth\n",
    "\n",
    "    # 贴边惩罚（矩形外框会有很高贴边率）\n",
    "    touch = _border_touch_ratio(path_rc, H, W, thr=3)\n",
    "    base *= (1.0 - min(0.85, 0.9 * touch))   # 最多压到 15%\n",
    "\n",
    "    # 颜色候选的小加成（有 hue 时优先 hue）\n",
    "    if kind == \"hue\":\n",
    "        base *= 1.15\n",
    "\n",
    "    return base\n",
    "\n",
    "\n",
    "def _norm01(a):\n",
    "    a = a.astype(np.float32)\n",
    "    mn, mx = a.min(), a.max()\n",
    "    return (a - mn) / (mx - mn + 1e-8)\n",
    "\n",
    "def _build_cost_image(crop_bgr, hue_center=None):\n",
    "    # 1) 线结构增强（对细长亮线特别友好）\n",
    "    gray = cv2.cvtColor(crop_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    vessel = sato(_norm01(gray), sigmas=tuple(range(1, 5)))   # 细到粗的多尺度\n",
    "    vessel_n = _norm01(vessel)\n",
    "\n",
    "    # 2) 可选颜色相似度（自动抓主色相，不强制指定）\n",
    "    cost = 1.0 - vessel_n   # vessel 强 => cost 低\n",
    "    if hue_center is not None:\n",
    "        hsv = cv2.cvtColor(crop_bgr, cv2.COLOR_BGR2HSV)\n",
    "        H, S, V = cv2.split(hsv)\n",
    "        # 色相圆距离（0~1），饱和度越高越可信\n",
    "        d = np.minimum(np.abs(H - hue_center), 180 - np.abs(H - hue_center)) / 90.0\n",
    "        color_penalty = _norm01(d) * (1.0 - _norm01(S)) * 0.5\n",
    "        cost = _norm01(cost + color_penalty)\n",
    "\n",
    "    # 3) 加一点常数避免 0 权重\n",
    "    return _norm01(cost) + 1e-3\n",
    "\n",
    "def _pick_hue_center(crop_bgr):\n",
    "    hsv = cv2.cvtColor(crop_bgr, cv2.COLOR_BGR2HSV)\n",
    "    H, S, V = cv2.split(hsv)\n",
    "    mask = (S >= 60) & (V >= 50)\n",
    "    if np.count_nonzero(mask) < 200:\n",
    "        return None\n",
    "    hist, _ = np.histogram(H[mask], bins=181, range=(0,181))\n",
    "    h = int(hist.argmax())\n",
    "    return h\n",
    "\n",
    "def _farthest_pair_on_mask(mask255):\n",
    "    # 取骨架后“直径”两端作为端点\n",
    "    from collections import deque\n",
    "    sk = (mask255 > 0).astype(np.uint8)\n",
    "    ys, xs = np.where(sk)\n",
    "    if len(xs) == 0: return None, None\n",
    "    pts = list(zip(xs, ys))\n",
    "    idx = {p:i for i,p in enumerate(pts)}\n",
    "    nbrs = [[] for _ in pts]\n",
    "    for k,(x,y) in enumerate(pts):\n",
    "        for dx in (-1,0,1):\n",
    "            for dy in (-1,0,1):\n",
    "                if dx==0 and dy==0: continue\n",
    "                q=(x+dx,y+dy); j=idx.get(q)\n",
    "                if j is not None: nbrs[k].append(j)\n",
    "    def bfs(start):\n",
    "        q = deque([start]); dist={start:0}; parent={start:-1}; last=start\n",
    "        while q:\n",
    "            u=q.popleft(); last=u\n",
    "            for v in nbrs[u]:\n",
    "                if v in dist: continue\n",
    "                dist[v]=dist[u]+1; parent[v]=u; q.append(v)\n",
    "        return last, dist, parent\n",
    "    a = 0\n",
    "    b,_,_  = bfs(a)\n",
    "    c,_,p2 = bfs(b)\n",
    "    # 回溯 b->c\n",
    "    path=[]; u=c\n",
    "    while u!=-1:\n",
    "        path.append(pts[u]); u=p2.get(u,-1)\n",
    "    return path[0], path[-1]   # 两端点 (x,y)\n",
    "\n",
    "def extract_curve_points_full(img_bgr, roi, max_gap_pct=0.06, debug=False):\n",
    "    \"\"\"\n",
    "    颜色无先验：多候选 + 去网格 + 骨架 + 测地最短路，拿到整段曲线\n",
    "    返回：按路径排序的像素坐标 (N,2)，全局坐标\n",
    "    \"\"\"\n",
    "    x0,y0,x1,y1 = roi\n",
    "    crop = img_bgr[y0:y1, x0:x1]\n",
    "\n",
    "    # ——(A) 先做一个“粗分割”得到若干候选——\n",
    "    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "    # 去掉网格与坐标轴\n",
    "    hor = cv2.morphologyEx(gray, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_RECT,(31,1)))\n",
    "    ver = cv2.morphologyEx(gray, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_RECT,(1,31)))\n",
    "    base = cv2.subtract(gray, cv2.max(hor, ver))\n",
    "    base = cv2.GaussianBlur(base, (3,3), 0)\n",
    "\n",
    "    hsv = cv2.cvtColor(crop, cv2.COLOR_BGR2HSV)\n",
    "    L,A,B = cv2.split(cv2.cvtColor(crop, cv2.COLOR_BGR2LAB))\n",
    "    chroma = np.sqrt((A-128.0)**2 + (B-128.0)**2)\n",
    "\n",
    "    # 色度+亮度\n",
    "    c_thr = np.percentile(chroma, 99)*0.30\n",
    "    v_thr = np.percentile(hsv[:,:,2], 75)*0.65\n",
    "    m_ch  = ((chroma>c_thr) & (hsv[:,:,2]>v_thr)).astype(np.uint8)*255\n",
    "    m_ch  = cv2.morphologyEx(m_ch, cv2.MORPH_OPEN,  np.ones((3,3),np.uint8), 1)\n",
    "    m_ch  = cv2.morphologyEx(m_ch, cv2.MORPH_DILATE, np.ones((3,3),np.uint8), 1)\n",
    "\n",
    "    # 色相峰（自动挑主色）\n",
    "    h0 = _pick_hue_center(crop)\n",
    "    if h0 is not None:\n",
    "        def _mask_h(hc):\n",
    "            band=14\n",
    "            if hc < band:\n",
    "                m1 = cv2.inRange(hsv,(0,60,50),(hc+band,255,255))\n",
    "                m2 = cv2.inRange(hsv,(180-(band-hc),60,50),(180,255,255))\n",
    "                return cv2.bitwise_or(m1,m2)\n",
    "            if hc+band>180:\n",
    "                m1 = cv2.inRange(hsv,(0,60,50),((hc+band)-180,255,255))\n",
    "                m2 = cv2.inRange(hsv,(hc-band,60,50),(180,255,255))\n",
    "                return cv2.bitwise_or(m1,m2)\n",
    "            return cv2.inRange(hsv,(hc-band,60,50),(hc+band,255,255))\n",
    "        m_h  = _mask_h(h0)\n",
    "    else:\n",
    "        m_h  = np.zeros_like(m_ch)\n",
    "\n",
    "    # Canny 作兜底\n",
    "    edges = cv2.Canny(base, 40, 100)\n",
    "\n",
    "    # 综合候选\n",
    "    mask0 = cv2.bitwise_or(m_ch, m_h)\n",
    "    mask0 = cv2.bitwise_or(mask0, edges)\n",
    "    mask0 = (mask0>0).astype(np.uint8)*255\n",
    "\n",
    "    # 👉(1) 杀边 & 贴边连通域过滤\n",
    "    mask0 = _kill_border(mask0, px=6)\n",
    "    num, lab, stats, _ = cv2.connectedComponentsWithStats(mask0, connectivity=8)\n",
    "    keep = np.zeros_like(mask0, np.uint8)\n",
    "    for i in range(1, num):\n",
    "        if stats[i, cv2.CC_STAT_AREA] < 150:  # 小噪点\n",
    "            continue\n",
    "        comp = (lab==i).astype(np.uint8)*255\n",
    "        if _component_touches_border(comp, px=4, frac=0.25):\n",
    "            continue\n",
    "        keep = cv2.bitwise_or(keep, comp)\n",
    "    mask = keep if keep.any() else mask0\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((5,5),np.uint8), 1)\n",
    "\n",
    "    # 👉(2) 骨架 + 剪枝（避免短枝当端点）\n",
    "    try:\n",
    "        import cv2.ximgproc as xi\n",
    "        skel = xi.thinning(mask)\n",
    "    except Exception:\n",
    "        from skimage.morphology import skeletonize\n",
    "        skel = (skeletonize((mask>0).astype(bool)).astype(np.uint8)*255)\n",
    "    skel = _prune_skeleton(skel, min_len=max(18, int(0.02*min(mask.shape))))\n",
    "    \n",
    "    pA, pB = _farthest_pair_on_mask(skel)   # 你的函数不变\n",
    "    if pA is None or pB is None:\n",
    "        return np.empty((0,2), dtype=int)\n",
    "\n",
    "    # 👉(3) “走廊约束”的代价图：走出走廊代价极高\n",
    "    corridor = cv2.dilate(mask, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,\n",
    "                    (max(7, int(0.015*(x1-x0))), max(7, int(0.015*(y1-y0))))))\n",
    "    corridor = (corridor>0).astype(np.uint8)\n",
    "    cost = _build_cost_image(crop, hue_center=h0).astype(np.float32)  # 你原来的\n",
    "    cost += 5.0 * _border_penalty(cost.shape, px=6)                   # 靠边惩罚\n",
    "    cost[ corridor==0 ] += 1e3                                         # 走廊外禁止\n",
    "\n",
    "    from skimage.graph import route_through_array\n",
    "    start = (pA[1], pA[0]); end = (pB[1], pB[0])\n",
    "    path_rc, _ = route_through_array(cost, start, end, geometric=True, fully_connected=True)\n",
    "    path_rc = np.array(path_rc, dtype=int)\n",
    "\n",
    "    # 回填全局坐标 + 轻微重采样（同你原来）\n",
    "    pts = np.column_stack([path_rc[:,1] + x0, path_rc[:,0] + y0])\n",
    "    d = np.sqrt(np.sum(np.diff(pts, axis=0)**2, axis=1)); s = np.insert(np.cumsum(d), 0, 0.0)\n",
    "    if s[-1] > 0:\n",
    "        N = min(600, max(200, pts.shape[0]))\n",
    "        si = np.linspace(0, s[-1], N)\n",
    "        xi = np.interp(si, s, pts[:,0]); yi = np.interp(si, s, pts[:,1])\n",
    "        pts = np.column_stack([xi, yi]).astype(np.float32)\n",
    "    if debug:\n",
    "        dbg = crop.copy()\n",
    "        for (x,y) in (pts - [x0,y0]).astype(int):\n",
    "            cv2.circle(dbg, (int(x),int(y)), 1, (0,255,0), -1)\n",
    "        cv2.imwrite(\"debug_curve_path.png\", dbg)\n",
    "    return pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "647d6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ocr_band_numbers(band_bgr, lang='eng', try_psm=(7,6,11,4), do_invert=(False,True), scales=(1.0, 1.5, 2.0)):\n",
    "    out=[]\n",
    "    for sc in scales:\n",
    "        band = cv2.resize(band_bgr, None, fx=sc, fy=sc, interpolation=cv2.INTER_CUBIC) if sc!=1.0 else band_bgr.copy()\n",
    "        gray = cv2.cvtColor(band, cv2.COLOR_BGR2GRAY)\n",
    "        for inv in do_invert:\n",
    "            g = gray if not inv else (255-gray)\n",
    "            bw = cv2.threshold(g,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "            bw = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, np.ones((3,3),np.uint8), 1)\n",
    "            for psm in try_psm:\n",
    "                cfg=f\"--oem 3 --psm {psm} {DIGIT_CONFIG_BASE}\"\n",
    "                data=pytesseract.image_to_data(bw, output_type=pytesseract.Output.DICT, config=cfg, lang=lang)\n",
    "                for i,txt in enumerate(data['text']):\n",
    "                    if not txt: continue\n",
    "                    raw=txt.strip(); val=_parse_num(raw)\n",
    "                    if val is None: continue\n",
    "                    x=int((data['left'][i]+data['width'][i]//2)/sc)\n",
    "                    y=int((data['top'][i] +data['height'][i]//2)/sc)\n",
    "                    out.append((x,y,val,raw))\n",
    "    # 位置去重（取众数）\n",
    "    uniq, used=[], np.zeros(len(out), bool)\n",
    "    for i,(x,y,v,r) in enumerate(out):\n",
    "        if used[i]: continue\n",
    "        group=[(x,y,v,r)]; used[i]=True\n",
    "        for j,(x2,y2,v2,r2) in enumerate(out[i+1:], start=i+1):\n",
    "            if used[j]: continue\n",
    "            if abs(x2-x)<=6 and abs(y2-y)<=6:\n",
    "                group.append((x2,y2,v2,r2)); used[j]=True\n",
    "        vals=[g[2] for g in group]; raws=[g[3] for g in group]\n",
    "        uniq.append((x,y,sorted(vals, key=lambda t: vals.count(t), reverse=True)[0],\n",
    "                         sorted(raws, key=lambda t: raws.count(t), reverse=True)[0]))\n",
    "    return uniq\n",
    "\n",
    "def _theil_sen(px, val):\n",
    "    px = px.astype(float); val = val.astype(float)\n",
    "    n = len(px); slopes=[]\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            if px[j]!=px[i]:\n",
    "                slopes.append((val[j]-val[i])/(px[j]-px[i]))\n",
    "    a = np.median(slopes)\n",
    "    b = np.median(val - a*px)\n",
    "    return a,b\n",
    "\n",
    "def _fit_line_robust(pxs, vals, alpha=0.90):\n",
    "    pxs = np.asarray(pxs, float)\n",
    "    vals = np.asarray(vals, float)\n",
    "    # 至少需要两个不同的 x\n",
    "    if len(np.unique(pxs)) < 2:\n",
    "        return 0.0, float(np.mean(vals))\n",
    "\n",
    "    # 1) 第一次 Theil–Sen 拟合\n",
    "    try:\n",
    "        a, b, _, _ = theilslopes(vals, pxs, alpha=alpha)  # y=vals, x=pxs\n",
    "    except Exception:\n",
    "        a, b = np.polyfit(pxs, vals, 1)\n",
    "\n",
    "    # 2) 残差剔错\n",
    "    pred = a * pxs + b\n",
    "    res  = np.abs(vals - pred)\n",
    "    mad  = np.median(np.abs(res - np.median(res))) + 1e-9\n",
    "    thr  = max(2.5 * mad, 0.02 * (vals.max() - vals.min() + 1e-9))\n",
    "    keep = res <= thr\n",
    "    if keep.sum() >= 2 and len(np.unique(pxs[keep])) >= 2:\n",
    "        try:\n",
    "            a, b, _, _ = theilslopes(vals[keep], pxs[keep], alpha=alpha)\n",
    "        except Exception:\n",
    "            a, b = np.polyfit(pxs[keep], vals[keep], 1)\n",
    "    return a, b\n",
    "\n",
    "\n",
    "def _fit_axis(img, roi, is_y=False, lang='eng',\n",
    "              band_h_frac=0.18, band_w_frac=0.20,\n",
    "              step_snap=0.5, debug=False):\n",
    "    H,W = img.shape[:2]\n",
    "    x0,y0,x1,y1 = roi\n",
    "    def clip_rect(xa,ya,xb,yb): return max(0,xa), max(0,ya), min(W,xb), min(H,yb)\n",
    "    bh = max(20, int(band_h_frac*(y1-y0)))\n",
    "    bw = max(30, int(band_w_frac*(x1-x0)))\n",
    "\n",
    "    # 额外：X 轴“内侧”带\n",
    "    x_inside = clip_rect(x0, y1 - max(16, int(0.12*(y1-y0))), x1, y1)\n",
    "    # 额外：Y 轴“内侧”带（你已有 yli，这里沿用）\n",
    "    xb = clip_rect(x0-5, y1,   x1+5, y1+bh)  # 下外\n",
    "    xt = clip_rect(x0-5, y0-bh, x1+5, y0)    # 上外\n",
    "    yl = clip_rect(x0-bw, y0-5, x0,   y1+5)  # 左外\n",
    "    yr = clip_rect(x1,   y0-5, x1+bw, y1+5)  # 右外\n",
    "    yli= clip_rect(x0,   y0,   x0+max(22,int(0.10*(x1-x0))), y1)  # 左内\n",
    "\n",
    "    if not is_y:\n",
    "        xs_b = _ocr_band_numbers(img[xb[1]:xb[3], xb[0]:xb[2]], lang=lang)\n",
    "        xs_t = _ocr_band_numbers(img[xt[1]:xt[3], xt[0]:xt[2]], lang=lang)\n",
    "        xs_i = _ocr_band_numbers(img[x_inside[1]:x_inside[3], x_inside[0]:x_inside[2]], lang=lang)\n",
    "        xs_b = [(x+xb[0], y+xb[1], v, r) for x,y,v,r in xs_b]\n",
    "        xs_t = [(x+xt[0], y+xt[1], v, r) for x,y,v,r in xs_t]\n",
    "        xs_i = [(x+x_inside[0], y+x_inside[1], v, r) for x,y,v,r in xs_i]\n",
    "        xs = xs_b + xs_t + xs_i\n",
    "        # 仅保留靠近上下边缘的\n",
    "        pts_raw = [(x,y,v,r) for (x,y,v,r) in xs\n",
    "                   if (y1-2<=y<=y1+bh+2) or (y0-bh-2<=y<=y0+2) or (y1-18<=y<=y1)]\n",
    "    else:\n",
    "        ys  = [(x+yl[0],y+yl[1],v,r) for x,y,v,r in _ocr_band_numbers(img[yl[1]:yl[3], yl[0]:yl[2]], lang=lang)]\n",
    "        ys += [(x+yr[0],y+yr[1],v,r) for x,y,v,r in _ocr_band_numbers(img[yr[1]:yr[3], yr[0]:yr[2]], lang=lang)]\n",
    "        ys += [(x+yli[0],y+yli[1],v,r) for x,y,v,r in _ocr_band_numbers(img[yli[1]:yli[3], yli[0]:yli[2]], lang=lang)]\n",
    "        pts_raw = [(x,y,v,r) for (x,y,v,r) in ys\n",
    "                   if (x0-bw-2<=x<=x0+12) or (x1-12<=x<=x1+bw+2) or (x0<=x<=x0+max(24,int(0.10*(x1-x0))))]\n",
    "\n",
    "    if debug: print(f\"[OCR raw] {('X','Y')[is_y]} candidates:\", len(pts_raw))\n",
    "    if len(pts_raw) < 2:\n",
    "        raise RuntimeError(\"刻度不足\")\n",
    "\n",
    "    # —— 像素相对位置 + 数值（带小数点丢失修正）——\n",
    "    pxs0, vals0, raws0 = [], [], []\n",
    "    for (x,y,v,r) in pts_raw:\n",
    "        px = (x - x0) if not is_y else (y1 - y)\n",
    "        vv = float(v)\n",
    "        if '.' not in r and abs(vv) >= 4:\n",
    "            if abs(vv) >= 40: vv /= 10.0\n",
    "            if abs(vv) >= 4:  vv /= 10.0\n",
    "        pxs0.append(px); vals0.append(vv); raws0.append(r)\n",
    "    pxs0 = np.asarray(pxs0, float); vals0 = np.asarray(vals0, float)\n",
    "\n",
    "    # —— 位置聚类：合并同一刻度的多次 OCR —— \n",
    "    order = np.argsort(pxs0); pxs0, vals0 = pxs0[order], vals0[order]\n",
    "    groups, cur = [], [0]\n",
    "    for i in range(1, len(pxs0)):\n",
    "        if abs(pxs0[i] - pxs0[cur[-1]]) <= 6:\n",
    "            cur.append(i)\n",
    "        else:\n",
    "            groups.append(cur); cur = [i]\n",
    "    groups.append(cur)\n",
    "    pxs = np.array([np.median(pxs0[g]) for g in groups])\n",
    "    vals = np.array([np.median(vals0[g]) for g in groups])\n",
    "\n",
    "    # —— 轻过滤 + 主簇选择（去掉 1e10 那堆）——\n",
    "    ok = np.isfinite(vals) & (np.abs(vals) <= 200)\n",
    "    pxs, vals = pxs[ok], vals[ok]\n",
    "    if len(pxs) >= 3:\n",
    "        dv = np.diff(np.sort(vals))\n",
    "        step_est = np.median(dv[dv>1e-6]) if np.any(dv>1e-6) else 0.5\n",
    "        eps = max(0.15*step_est, 0.25)\n",
    "        labels = DBSCAN(eps=eps, min_samples=2).fit(vals.reshape(-1,1)).labels_\n",
    "        best_idx, best_cnt = None, 0\n",
    "        for lab in set(labels):\n",
    "            if lab == -1: continue\n",
    "            idx = np.where(labels==lab)[0]\n",
    "            if len(idx)>best_cnt and np.median(np.abs(vals[idx]))<20:\n",
    "                best_cnt, best_idx = len(idx), idx\n",
    "        if best_idx is not None:\n",
    "            pxs, vals = pxs[best_idx], vals[best_idx]\n",
    "    if len(pxs) < 2:\n",
    "        # 分位裁剪兜底\n",
    "        lo, hi = np.percentile(vals0, [10,90])\n",
    "        m = (vals0>=lo)&(vals0<=hi)\n",
    "        pxs, vals = pxs0[m], vals0[m]\n",
    "\n",
    "    # 吸附到 0.5（可按需要关掉）\n",
    "    if step_snap:\n",
    "        vals = np.round(vals/step_snap)*step_snap\n",
    "\n",
    "    # 单调性 + 稳健拟合\n",
    "    ord2 = np.argsort(pxs); pxs, vals = pxs[ord2], vals[ord2]\n",
    "    keep=[0]\n",
    "    for i in range(1, len(vals)):\n",
    "        if vals[i] + 1e-6 >= vals[keep[-1]]:\n",
    "            keep.append(i)\n",
    "    if len(keep) >= 2:\n",
    "        pxs, vals = pxs[keep], vals[keep]\n",
    "\n",
    "    if len(np.unique(pxs)) < 2:\n",
    "        raise RuntimeError(\"有效刻度不足（清洗后）\")\n",
    "\n",
    "    a,b = _fit_line_robust(pxs, vals, alpha=0.90)\n",
    "    if debug: print(f\"[{('X','Y')[is_y]} fit] n={len(pxs)} slope={a:.6f} intercept={b:.6f}\")\n",
    "    return a,b, list(zip(pxs.tolist(), vals.tolist()))\n",
    "\n",
    "def fit_axis_maps(img, roi, lang='eng', step_snap=0.5):\n",
    "    ax,bx, x_dbg = _fit_axis(img, roi, is_y=False, lang=lang, step_snap=step_snap)\n",
    "    ay,by, y_dbg = _fit_axis(img, roi, is_y=True,  lang=lang, step_snap=step_snap)\n",
    "    # x = ax*(px - x0) + bx\n",
    "    # y = ay*(y1 - py) + by\n",
    "    return (ax,bx), (ay,by), x_dbg, y_dbg\n",
    "\n",
    "def convert_points_to_data(curve_pts, img_shape, x_map, y_map, roi):\n",
    "    x0,y0,x1,y1 = roi\n",
    "    ax,bx = x_map; ay,by = y_map\n",
    "    out=[]\n",
    "    for (px,py) in curve_pts:\n",
    "        x = ax*(px - x0) + bx\n",
    "        y = ay*(y1 - py) + by\n",
    "        out.append((x,y))\n",
    "    return np.array(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53090dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plausible_curve_df(df, axis=(\"z\",\"x\"), z_col=1, v_col=0,\n",
    "                       min_pts=20, min_numeric_ratio=0.7,\n",
    "                       max_abs_z=1e3, max_span_z=1e4,\n",
    "                       return_arrays=False):\n",
    "    import numpy as np, pandas as pd\n",
    "    if not isinstance(df, pd.DataFrame) or df.shape[1] <= max(z_col, v_col):\n",
    "        return (False, None, None) if return_arrays else False\n",
    "\n",
    "    z_raw = pd.to_numeric(df.iloc[:, z_col], errors=\"coerce\").values\n",
    "    v_raw = pd.to_numeric(df.iloc[:, v_col], errors=\"coerce\").values\n",
    "    ok = np.isfinite(z_raw) & np.isfinite(v_raw)\n",
    "    if ok.mean() < min_numeric_ratio:\n",
    "        return (False, None, None) if return_arrays else False\n",
    "\n",
    "    z0, v0 = z_raw[ok], v_raw[ok]\n",
    "    if len(z0) < min_pts:\n",
    "        return (False, None, None) if return_arrays else False\n",
    "\n",
    "    # —— 先在原顺序上检查“非严格单调”（允许重复、允许微小噪声）——\n",
    "    eps = 1e-6\n",
    "    dz0 = np.diff(z0)\n",
    "    mono_inc = np.all(dz0 >= -eps)\n",
    "    mono_dec = np.all(dz0 <=  eps)\n",
    "    if not (mono_inc or mono_dec):\n",
    "        return (False, None, None) if return_arrays else False\n",
    "\n",
    "    # 统一升序\n",
    "    if mono_dec and not mono_inc:\n",
    "        z0 = z0[::-1]; v0 = v0[::-1]\n",
    "\n",
    "    # 排序 & 去重（同一 Z 留第一个）\n",
    "    order = np.argsort(z0); z, v = z0[order], v0[order]\n",
    "    uniq_z, uniq_idx = np.unique(z, return_index=True)\n",
    "    z, v = z[uniq_idx], v[uniq_idx]\n",
    "\n",
    "    # 范围检查\n",
    "    if not np.isfinite(z).all() or np.max(np.abs(z)) > max_abs_z:\n",
    "        return (False, None, None) if return_arrays else False\n",
    "    span = z.max() - z.min()\n",
    "    if span <= 1e-6 or span > max_span_z:\n",
    "        return (False, None, None) if return_arrays else False\n",
    "\n",
    "    return (True, z, v) if return_arrays else True\n",
    "\n",
    "\n",
    "def chart_to_series(img_path: str, axis=(\"z\",\"x\"), use_deplot_first=True, lang='eng', out_dir=None):\n",
    "    \"\"\"\n",
    "    固定约定：横轴= X 或 Y，纵轴= Z。\n",
    "    返回 DataFrame 两列（[\"z\",\"x\"] 或 [\"z\",\"y\"]），不会做轴自动检测。\n",
    "    axis 仅用于输出列名，不改变取值方向。\n",
    "    \"\"\"\n",
    "    assert axis in ((\"z\",\"x\"), (\"z\",\"y\")), \"axis 只支持 ('z','x') 或 ('z','y')\"\n",
    "    img  = cv2.imread(img_path); assert img is not None, f\"读图失败: {img_path}\"\n",
    "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "    # 1) DePlot 优先（如果你不想用，调用时传 use_deplot_first=False 即可）\n",
    "    if use_deplot_first:\n",
    "        try:\n",
    "            deplot = DePlotWrapper()\n",
    "            if deplot.available():\n",
    "                df_raw = deplot.infer_table(img, axis_hint=(axis[1], axis[0]))\n",
    "                if isinstance(df_raw, pd.DataFrame) and df_raw.shape[1] >= 2:\n",
    "                    ok, z, v = plausible_curve_df(df_raw, z_col=0, v_col=1, return_arrays=True)\n",
    "                    if ok:\n",
    "                        out = pd.DataFrame({axis[0]: z, axis[1]: v})\n",
    "                        if out_dir:\n",
    "                            os.makedirs(out_dir, exist_ok=True)\n",
    "                            df_to_csv_safe(out, os.path.join(out_dir, f\"{base}_{axis[1]}-{axis[0]}_deplot.csv\"))\n",
    "                        return out, {\"method\": \"deplot\"}\n",
    "                    else:\n",
    "                        print(\"[DePlot] 输出不可信，回退 OCR。\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"[DePlot] 失败，回退到 OCR：\", e)\n",
    "\n",
    "    # 2) 回退：像素+OCR（自动颜色版本）\n",
    "    roi = find_plot_roi(img)\n",
    "    pts = extract_curve_points_full(img, roi)  # YOZ 建议 True\n",
    "    if len(pts) == 0:\n",
    "        raise RuntimeError(\"曲线像素未检测到（auto）\")\n",
    "\n",
    "    # 轴标定：得到像素→数值的线性映射\n",
    "    x_map, y_map, x_dbg, y_dbg = fit_axis_maps(img, roi, lang=lang, step_snap=0.5)\n",
    "\n",
    "    # 像素点 → (X_or_Y, Z) 数值（固定：横轴=X/Y、纵轴=Z）\n",
    "    xy = convert_points_to_data(pts, img.shape, x_map, y_map, roi)\n",
    "    z_series = xy[:, 1]  # 竖直方向（纵轴）= Z\n",
    "    v_series = xy[:, 0]  # 水平方向（横轴）= X 或 Y\n",
    "\n",
    "    # 排序 & 去重（按 z）\n",
    "    order = np.argsort(z_series); z_series, v_series = z_series[order], v_series[order]\n",
    "    uniq_z, uniq_idx = np.unique(z_series, return_index=True)\n",
    "    z_series, v_series = z_series[uniq_idx], v_series[uniq_idx]\n",
    "\n",
    "    df = pd.DataFrame({axis[0]: z_series, axis[1]: v_series})\n",
    "\n",
    "    if out_dir:\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        save_overlay(os.path.join(out_dir, f\"{base}_overlay.png\"), img, roi, pts)\n",
    "        df_to_csv_safe(df, os.path.join(out_dir, f\"{base}_{axis[1]}-{axis[0]}.csv\"))\n",
    "        with open(os.path.join(out_dir, f\"{base}_tick_debug.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({\"x_map\": x_map, \"y_map\": y_map, \"x_dbg\": x_dbg, \"y_dbg\": y_dbg, \"roi\": roi},\n",
    "                      f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return df, {\"method\": \"ocr\", \"roi\": roi, \"x_map\": x_map, \"y_map\": y_map}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7acf0cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def rebuild_3d_from_xoz_yoz(df_xoz: pd.DataFrame, df_yoz: pd.DataFrame, \n",
    "                            n_samples: int = 200, smooth_sigma: Optional[float]=None):\n",
    "    # df_xoz: columns [\"z\",\"x\"]; df_yoz: [\"z\",\"y\"]\n",
    "    z1, x = df_xoz[\"z\"].values, df_xoz[\"x\"].values\n",
    "    z2, y = df_yoz[\"z\"].values, df_yoz[\"y\"].values\n",
    "    # 去重 & 单调（防止反复水平段）\n",
    "    def uniq_sort(z, v):\n",
    "        order = np.argsort(z); z,v = z[order], v[order]\n",
    "        uniq_z, uniq_idx = np.unique(z, return_index=True)\n",
    "        return uniq_z, v[uniq_idx]\n",
    "    z1,x = uniq_sort(z1,x)\n",
    "    z2,y = uniq_sort(z2,y)\n",
    "    print(f'z1: {len(z1)} points, z2: {len(z2)} points')\n",
    "    print(f'z1:' + ', '.join(f'{z:.3f}' for z in z1[:5]) + ' ...')\n",
    "    print(f'z2:' + ', '.join(f'{z:.3f}' for z in z2[:5]) + ' ...')\n",
    "    \n",
    "    print(f'x: {len(x)} points, y: {len(y)} points')\n",
    "    print(f'x:' + ', '.join(f'{v:.3f}' for v in x[:5]) + ' ...')\n",
    "    print(f'y:' + ', '.join(f'{v:.3f}' for v in y[:5]) + ' ...')\n",
    "\n",
    "    # 公共 z 区间\n",
    "    z_min = max(z1.min(), z2.min())\n",
    "    z_max = min(z1.max(), z2.max())\n",
    "    if not np.isfinite(z_min) or not np.isfinite(z_max) or z_max<=z_min:\n",
    "        raise RuntimeError(\"公共 z 区间无效，请检查两张图的轴是否一致。\")\n",
    "\n",
    "    zq = np.linspace(z_min, z_max, n_samples)\n",
    "    fx = interp1d(z1, x, kind=\"linear\", fill_value=\"extrapolate\")\n",
    "    fy = interp1d(z2, y, kind=\"linear\", fill_value=\"extrapolate\")\n",
    "    xq = fx(zq); yq = fy(zq)\n",
    "\n",
    "    # 可选平滑（简单高斯）\n",
    "    if smooth_sigma and smooth_sigma>0:\n",
    "        import scipy.ndimage as ndi\n",
    "        xq = ndi.gaussian_filter1d(xq, sigma=smooth_sigma, mode=\"nearest\")\n",
    "        yq = ndi.gaussian_filter1d(yq, sigma=smooth_sigma, mode=\"nearest\")\n",
    "\n",
    "    pts3d = np.column_stack([xq, yq, zq])  # (N,3)\n",
    "    return pts3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e52f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1) 提取像素坐标\n",
    "# ---------------------------\n",
    "def extract_curve_pixels(img_path):\n",
    "    img = cv2_imread_any(img_path)\n",
    "    assert img is not None, f\"读图失败: {img_path}\"\n",
    "    roi = find_plot_roi(img)\n",
    "    pts_px = extract_curve_points_full(img, roi)  # 你的“整段曲线”函数\n",
    "    if pts_px is None or len(pts_px) == 0:\n",
    "        raise RuntimeError(\"未提取到曲线像素点\")\n",
    "    # 统一成 float64，形如 [[px,py], ...]，是**全局像素坐标**\n",
    "    pts_px = np.asarray(pts_px, dtype=np.float64)\n",
    "    return img, roi, pts_px\n",
    "\n",
    "# ---------------------------\n",
    "# 2A) 用已知范围做线性映射（最省心）\n",
    "# plane='xoz' 或 'yoz'；范围传 (min, max)\n",
    "# ---------------------------\n",
    "def map_pixels_by_ranges(pts_px, roi, plane='xoz',\n",
    "                         x_range=None, y_range=None, z_range=None):\n",
    "    x0,y0,x1,y1 = roi\n",
    "    W = (x1 - x0); H = (y1 - y0)\n",
    "    assert W > 0 and H > 0\n",
    "\n",
    "    px = pts_px[:,0]; py = pts_px[:,1]\n",
    "\n",
    "    # z 垂直：注意图像坐标向下增，物理 z 向上增\n",
    "    assert z_range is not None, \"必须提供 z_range=(z_min,z_max)\"\n",
    "    z_min, z_max = z_range\n",
    "    z = z_min + ( (y1 - py) / H ) * (z_max - z_min)\n",
    "\n",
    "    if plane.lower() == 'xoz':\n",
    "        assert x_range is not None, \"xoz 平面需要 x_range=(x_min,x_max)\"\n",
    "        x_min, x_max = x_range\n",
    "        x = x_min + ( (px - x0) / W ) * (x_max - x_min)\n",
    "        df = pd.DataFrame({\"z\": z, \"x\": x})\n",
    "    else:  # 'yoz'\n",
    "        assert y_range is not None, \"yoz 平面需要 y_range=(y_min,y_max)\"\n",
    "        y_min, y_max = y_range\n",
    "        y = y_min + ( (px - x0) / W ) * (y_max - y_min)\n",
    "        df = pd.DataFrame({\"z\": z, \"y\": y})\n",
    "\n",
    "    # 按 z 排序并去 z 重复\n",
    "    order = np.argsort(df[\"z\"].values)\n",
    "    df = df.iloc[order]\n",
    "    df = df.drop_duplicates(subset=[\"z\"], keep=\"first\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# ---------------------------\n",
    "# 2B) 用“原点+轴上标定点”做映射（更精确）\n",
    "# origin_px=(px0,py0) 对应 origin_phys=(x0,z0)；x_anchor_px 在 x 轴方向（同一 py），z_anchor_px 在 z 轴方向（同一 px）\n",
    "# x_anchor_phys / z_anchor_phys 是它们各自的物理值\n",
    "# ---------------------------\n",
    "def map_pixels_by_anchors(pts_px, plane, origin_px, x_anchor_px=None, z_anchor_px=None,\n",
    "                          origin_phys=(0.0,0.0), x_anchor_phys=None, z_anchor_phys=None):\n",
    "    \"\"\"\n",
    "    plane='xoz' 或 'yoz'\n",
    "    - 对 xoz：返回 DataFrame(['z','x'])\n",
    "    - 对 yoz：返回 DataFrame(['z','y'])\n",
    "    \"\"\"\n",
    "    (px0, py0) = origin_px\n",
    "    (x0_phys, z0_phys) = origin_phys\n",
    "\n",
    "    px = pts_px[:,0]; py = pts_px[:,1]\n",
    "\n",
    "    # Z 轴（竖直）标定：用 origin 和 z_anchor 求比例（注意 y 反向）\n",
    "    assert z_anchor_px is not None and z_anchor_phys is not None, \"需要提供 z 轴标定点\"\n",
    "    (pxZ, pyZ) = z_anchor_px\n",
    "    sz = (z_anchor_phys - z0_phys) / (py0 - pyZ + 1e-9)  # 防 0\n",
    "    z = z0_phys + sz * (py0 - py)  # y 反向\n",
    "\n",
    "    # 水平轴（x 或 y）\n",
    "    assert x_anchor_px is not None and x_anchor_phys is not None, \"需要提供水平轴标定点\"\n",
    "    (pxX, pyX) = x_anchor_px\n",
    "    sx = (x_anchor_phys - x0_phys) / (pxX - px0 + 1e-9)\n",
    "\n",
    "    if plane.lower() == 'xoz':\n",
    "        x = x0_phys + sx * (px - px0)\n",
    "        df = pd.DataFrame({\"z\": z, \"x\": x})\n",
    "    else:\n",
    "        y = x0_phys + sx * (px - px0)  # 这里“水平轴”的物理量是 y\n",
    "        df = pd.DataFrame({\"z\": z, \"y\": y})\n",
    "\n",
    "    # 按 z 排序并去重\n",
    "    order = np.argsort(df[\"z\"].values)\n",
    "    df = df.iloc[order]\n",
    "    df = df.drop_duplicates(subset=[\"z\"], keep=\"first\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3) 保存像素坐标（便于后处理/复核）\n",
    "# ---------------------------\n",
    "def save_pixels_csv(path, pts_px):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    df = pd.DataFrame({\"px\": pts_px[:,0], \"py\": pts_px[:,1]})\n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f81b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a78ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "XOZ_PATH = \"Data/初赛数据-血管造影图像/自建-二维投影曲线图像/1/xoz平面投影.png\"\n",
    "YOZ_PATH = Path(\"Data/初赛数据-血管造影图像/自建-二维投影曲线图像/1/yoz平面投影.png\")\n",
    "OUT_DIR  = Path(\"./out_chart3d\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)  \n",
    "\n",
    "\n",
    "_, roi_xoz, pts_xoz = extract_curve_pixels(XOZ_PATH)\n",
    "df_xoz = map_pixels_by_ranges(pts_xoz, roi_xoz, plane=\"xoz\",\n",
    "                              x_range=(-0.55, 3.0), z_range=(-0.9, 2.34))\n",
    "df_xoz.to_csv(f\"{OUT_DIR}/1_xoz_zx.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "_, roi_yoz, pts_yoz = extract_curve_pixels(YOZ_PATH)\n",
    "df_yoz = map_pixels_by_ranges(pts_yoz, roi_yoz, plane=\"yoz\",\n",
    "                              y_range=(-1.1, -0.3), z_range=(-0.9, 2.34))\n",
    "df_yoz.to_csv(f\"{OUT_DIR}/1_yoz_zy.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b0e1a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ca24631b10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zx = pd.read_csv('out_chart3d/1_xoz_zx.csv')\n",
    "x = zx['x']\n",
    "z = zx['z']\n",
    "plt.scatter(x, z, s=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d9943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dicom310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
